{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T23:14:45.083313Z",
     "start_time": "2020-11-17T23:14:44.818195Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: The Dask Engine for Modin is experimental.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc\n",
    "from time import time, sleep, strftime, localtime\n",
    "\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import modin.pandas as mpd\n",
    "import vaex\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import sum, avg\n",
    "# pandas on ray has moved to Modin\n",
    "# import ray.dataframe as rpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T22:55:27.722264Z",
     "start_time": "2020-11-17T22:55:27.699399Z"
    }
   },
   "outputs": [],
   "source": [
    "# data based on https://www.kaggle.com/c/ieee-fraud-detection/data\n",
    "folder = \"/home/vaclav/Data/Kaggle/EEE-CIS_Fraud_Detection\"\n",
    "files = [\"train_transaction.csv\", \"train_identity.csv\"]\n",
    "paths = [os.path.join(folder, f) for f in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T22:55:27.733967Z",
     "start_time": "2020-11-17T22:55:27.727006Z"
    }
   },
   "outputs": [],
   "source": [
    "stats = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T22:55:27.750077Z",
     "start_time": "2020-11-17T22:55:27.737957Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.4'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T22:56:19.465362Z",
     "start_time": "2020-11-17T22:55:27.767439Z"
    }
   },
   "outputs": [],
   "source": [
    "stats[\"pandas\"] = {}\n",
    "s = stats[\"pandas\"]\n",
    "\n",
    "ts = time()\n",
    "df = pd.read_csv(paths[0])\n",
    "te = time()\n",
    "s[\"load_transactions\"] = te-ts\n",
    "\n",
    "ts = time()\n",
    "df2 = pd.read_csv(paths[1])\n",
    "te = time()\n",
    "s[\"load_identity\"] = te-ts\n",
    "\n",
    "ts = time()\n",
    "dff = df.merge(df2, on=\"TransactionID\")\n",
    "te = time()\n",
    "s[\"merge\"] = te-ts\n",
    "\n",
    "ts = time()\n",
    "grp = dff.groupby([\"isFraud\",\"ProductCD\",\"card4\",\"card6\",\"id_15\",\"id_31\"])[\"TransactionAmt\"].agg([\"mean\",\"sum\"])\n",
    "te = time()\n",
    "s[\"aggregation\"] = te-ts\n",
    "\n",
    "ts = time()\n",
    "dff.sort_values(by=[\"card1\",\"addr1\",\"D9\"], inplace=True)\n",
    "dff.sort_values(by=[\"addr1\",\"D9\",\"card1\"], inplace=True)\n",
    "dff.sort_values(by=[\"D9\",\"card1\",\"addr1\"], inplace=True)\n",
    "te = time()\n",
    "s[\"sorting\"] = te-ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T22:56:19.519391Z",
     "start_time": "2020-11-17T22:56:19.472412Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pandas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aggregation</th>\n",
       "      <td>0.066574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>load_identity</th>\n",
       "      <td>0.550774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>load_transactions</th>\n",
       "      <td>18.682878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merge</th>\n",
       "      <td>2.118241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sorting</th>\n",
       "      <td>1.177349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      pandas\n",
       "aggregation         0.066574\n",
       "load_identity       0.550774\n",
       "load_transactions  18.682878\n",
       "merge               2.118241\n",
       "sorting             1.177349"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.to_pickle(\"data/dff.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4553, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Because julia groups by including N\\A, let's just check that number of groups matches\n",
    "grp = dff[[\"isFraud\",\"ProductCD\",\"card4\",\"card6\",\"id_15\",\"id_31\",\"TransactionAmt\"]].fillna(\"~U~\")\\\n",
    ".groupby([\"isFraud\",\"ProductCD\",\"card4\",\"card6\",\"id_15\",\"id_31\"])[\"TransactionAmt\"].agg([\"mean\",\"sum\"])\n",
    "grp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T22:56:19.550559Z",
     "start_time": "2020-11-17T22:56:19.524963Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean(wait_time: int=15):\n",
    "    \"\"\"Cleans created DataFrames and call the garbage collector to actions. Wait for 15s by default\"\"\"\n",
    "    df, df2, dff, grp = None, None, None, None\n",
    "    gc.collect()\n",
    "    sleep(wait_time)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T22:56:34.718818Z",
     "start_time": "2020-11-17T22:56:19.559830Z"
    }
   },
   "outputs": [],
   "source": [
    "clean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T22:56:34.813222Z",
     "start_time": "2020-11-17T22:56:34.780299Z"
    }
   },
   "outputs": [],
   "source": [
    "def list_variables_memory_usage() -> dict:\n",
    "    \"\"\"Memory of existing local variables\"\"\"\n",
    "    local_vars = list(locals().items())\n",
    "    return {var: sys.getsizeof(obj) for var, obj in local_vars}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask\n",
    "When to use dask - https://docs.dask.org/en/latest/dataframe.html#common-uses-and-anti-uses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T22:57:00.280745Z",
     "start_time": "2020-11-17T22:56:34.844985Z"
    }
   },
   "outputs": [],
   "source": [
    "stats[\"dask\"] = {}\n",
    "s = stats[\"dask\"]\n",
    "\n",
    "ts = time()\n",
    "df = dd.read_csv(paths[0])\n",
    "te = time()\n",
    "s[\"load_transactions\"] = te-ts\n",
    "\n",
    "ts = time()\n",
    "df2 = dd.read_csv(paths[1])\n",
    "te = time()\n",
    "s[\"load_identity\"] = te-ts\n",
    "\n",
    "ts = time()\n",
    "dff = df.merge(df2, on=\"TransactionID\")\n",
    "te = time()\n",
    "s[\"merge\"] = te-ts\n",
    "\n",
    "# the difference is that we call compute method, which runs all the computations at this point\n",
    "ts = time()\n",
    "grp = dff.groupby([\"isFraud\",\"ProductCD\",\"card4\",\"card6\",\"id_15\",\"id_31\"])[\"TransactionAmt\"]\\\n",
    "    .agg([\"mean\",\"sum\"])\\\n",
    "    .compute()\n",
    "te = time()\n",
    "s[\"aggregation\"] = te-ts\n",
    "\n",
    "# parallel soring is tricky that is why there are only work arounds in dask. \n",
    "ts = time()\n",
    "dff.set_index(\"card1\").compute()\n",
    "te = time()\n",
    "s[\"sorting\"] = te-ts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T22:57:15.539155Z",
     "start_time": "2020-11-17T22:57:00.286799Z"
    }
   },
   "outputs": [],
   "source": [
    "clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T22:57:15.580380Z",
     "start_time": "2020-11-17T22:57:15.546567Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pandas</th>\n",
       "      <th>dask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>load_transactions</th>\n",
       "      <td>18.682878</td>\n",
       "      <td>0.059999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>load_identity</th>\n",
       "      <td>0.550774</td>\n",
       "      <td>0.015863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merge</th>\n",
       "      <td>2.118241</td>\n",
       "      <td>0.058240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aggregation</th>\n",
       "      <td>0.066574</td>\n",
       "      <td>17.411429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sorting</th>\n",
       "      <td>1.177349</td>\n",
       "      <td>49.431917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      pandas       dask\n",
       "load_transactions  18.682878   0.059999\n",
       "load_identity       0.550774   0.015863\n",
       "merge               2.118241   0.058240\n",
       "aggregation         0.066574  17.411429\n",
       "sorting             1.177349  49.431917"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats[\"dask_indexed\"] = {}\n",
    "s = stats[\"dask_indexed\"]\n",
    "\n",
    "ts = time()\n",
    "df = dd.read_csv(paths[0]).set_index(\"TransactionID\")\n",
    "te = time()\n",
    "s[\"load_transactions\"] = te-ts\n",
    "\n",
    "ts = time()\n",
    "df2 = dd.read_csv(paths[1]).set_index(\"TransactionID\")\n",
    "te = time()\n",
    "s[\"load_identity\"] = te-ts\n",
    "\n",
    "ts = time()\n",
    "dff = df.merge(df2, left_index=True, right_index=True)\n",
    "te = time()\n",
    "s[\"merge\"] = te-ts\n",
    "\n",
    "# the difference is that we call compute method, which runs all the computations at this point\n",
    "ts = time()\n",
    "grp = dff.groupby([\"isFraud\",\"ProductCD\",\"card4\",\"card6\",\"id_15\",\"id_31\"])[\"TransactionAmt\"]\\\n",
    "    .agg([\"mean\",\"sum\"])\\\n",
    "    .compute()\n",
    "te = time()\n",
    "s[\"aggregation\"] = te-ts\n",
    "\n",
    "# parallel soring is tricky that is why there are only work arounds in dask. \n",
    "ts = time()\n",
    "dff.set_index(\"card1\").compute()\n",
    "te = time()\n",
    "s[\"sorting\"] = te-ts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pandas</th>\n",
       "      <th>dask</th>\n",
       "      <th>dask_indexed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>load_transactions</th>\n",
       "      <td>18.682878</td>\n",
       "      <td>0.059999</td>\n",
       "      <td>10.035912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>load_identity</th>\n",
       "      <td>0.550774</td>\n",
       "      <td>0.015863</td>\n",
       "      <td>0.569751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merge</th>\n",
       "      <td>2.118241</td>\n",
       "      <td>0.058240</td>\n",
       "      <td>0.049744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aggregation</th>\n",
       "      <td>0.066574</td>\n",
       "      <td>17.411429</td>\n",
       "      <td>15.891529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sorting</th>\n",
       "      <td>1.177349</td>\n",
       "      <td>49.431917</td>\n",
       "      <td>53.414108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      pandas       dask  dask_indexed\n",
       "load_transactions  18.682878   0.059999     10.035912\n",
       "load_identity       0.550774   0.015863      0.569751\n",
       "merge               2.118241   0.058240      0.049744\n",
       "aggregation         0.066574  17.411429     15.891529\n",
       "sorting             1.177349  49.431917     53.414108"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean()\n",
    "pd.DataFrame(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T22:29:19.438715Z",
     "start_time": "2020-11-17T22:29:19.429209Z"
    }
   },
   "source": [
    "# Vaex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T23:03:06.560013Z",
     "start_time": "2020-11-17T23:03:06.545427Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vaex-core': '2.0.3',\n",
       " 'vaex-viz': '0.4.0',\n",
       " 'vaex-hdf5': '0.6.0',\n",
       " 'vaex-server': '0.3.1',\n",
       " 'vaex-astro': '0.7.0',\n",
       " 'vaex-jupyter': '0.5.2',\n",
       " 'vaex-ml': '0.9.0',\n",
       " 'vaex-arrow': '0.5.1'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vaex.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T23:04:01.165275Z",
     "start_time": "2020-11-17T23:03:06.562006Z"
    }
   },
   "outputs": [],
   "source": [
    "tool = \"vaex\"\n",
    "stats[tool] = {}\n",
    "s = stats[tool]\n",
    "\n",
    "\n",
    "ts = time()\n",
    "df = vaex.open(paths[0])\n",
    "te = time()\n",
    "s[\"load_transactions\"] = te-ts\n",
    "\n",
    "ts = time()\n",
    "df2 = vaex.open(paths[1])\n",
    "te = time()\n",
    "s[\"load_identity\"] = te-ts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T23:04:01.642707Z",
     "start_time": "2020-11-17T23:04:01.176085Z"
    }
   },
   "outputs": [],
   "source": [
    "ts = time()\n",
    "dff = df.join(df2, on=\"TransactionID\")\n",
    "te = time()\n",
    "s[\"merge\"] = te-ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T23:04:03.395316Z",
     "start_time": "2020-11-17T23:04:01.645742Z"
    }
   },
   "outputs": [],
   "source": [
    "# the difference is that we call compute method, which runs all the computations at this point\n",
    "ts = time()\n",
    "grp = dff.groupby([dff[\"isFraud\"],dff[\"ProductCD\"],dff[\"card4\"],dff[\"card6\"],dff[\"id_15\"],dff[\"id_31\"]], \n",
    "                  agg=[vaex.agg.mean('TransactionAmt'), vaex.agg.sum('TransactionAmt')])\n",
    "te = time()\n",
    "s[\"aggregation\"] = te-ts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the difference is that we call compute method, which runs all the computations at this point\n",
    "ts = time()\n",
    "dff_s = dff.sort(by=[\"card1\",\"addr1\",\"D9\"])\n",
    "dff_s = dff.sort(by=[\"addr1\",\"D9\",\"card1\"])\n",
    "dff_s = dff.sort(by=[\"D9\",\"card1\",\"addr1\"])\n",
    "te = time()\n",
    "s[\"sorting\"] = te-ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T23:04:03.469428Z",
     "start_time": "2020-11-17T23:04:03.423857Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pandas</th>\n",
       "      <th>dask</th>\n",
       "      <th>dask_indexed</th>\n",
       "      <th>vaex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>load_transactions</th>\n",
       "      <td>18.682878</td>\n",
       "      <td>0.059999</td>\n",
       "      <td>10.035912</td>\n",
       "      <td>17.666177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>load_identity</th>\n",
       "      <td>0.550774</td>\n",
       "      <td>0.015863</td>\n",
       "      <td>0.569751</td>\n",
       "      <td>0.884425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merge</th>\n",
       "      <td>2.118241</td>\n",
       "      <td>0.058240</td>\n",
       "      <td>0.049744</td>\n",
       "      <td>0.143270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aggregation</th>\n",
       "      <td>0.066574</td>\n",
       "      <td>17.411429</td>\n",
       "      <td>15.891529</td>\n",
       "      <td>0.494523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sorting</th>\n",
       "      <td>1.177349</td>\n",
       "      <td>49.431917</td>\n",
       "      <td>53.414108</td>\n",
       "      <td>1.108287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      pandas       dask  dask_indexed       vaex\n",
       "load_transactions  18.682878   0.059999     10.035912  17.666177\n",
       "load_identity       0.550774   0.015863      0.569751   0.884425\n",
       "merge               2.118241   0.058240      0.049744   0.143270\n",
       "aggregation         0.066574  17.411429     15.891529   0.494523\n",
       "sorting             1.177349  49.431917     53.414108   1.108287"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T23:04:18.930053Z",
     "start_time": "2020-11-17T23:04:03.543914Z"
    }
   },
   "outputs": [],
   "source": [
    "clean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark\n",
    "Java must be installed. (e.g. Ubuntu 18 - https://www.digitalocean.com/community/tutorials/how-to-install-java-with-apt-on-ubuntu-18-04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T23:04:27.010489Z",
     "start_time": "2020-11-17T23:04:18.932048Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext()\n",
    "sc.version\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T23:04:29.416261Z",
     "start_time": "2020-11-17T23:04:27.011485Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create my_spark\n",
    "my_spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"Pandas Alternative\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T23:05:33.528531Z",
     "start_time": "2020-11-17T23:04:29.419253Z"
    }
   },
   "outputs": [],
   "source": [
    "tool = \"spark\"\n",
    "stats[tool] = {}\n",
    "s = stats[tool]\n",
    "\n",
    "\n",
    "ts = time()\n",
    "df = my_spark.read.csv(paths[0],inferSchema = True,header= True) \n",
    "te = time()\n",
    "s[\"load_transactions\"] = te-ts\n",
    "\n",
    "ts = time()\n",
    "df2 = my_spark.read.csv(paths[1],inferSchema = True,header= True) \n",
    "te = time()\n",
    "s[\"load_identity\"] = te-ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T23:05:33.849489Z",
     "start_time": "2020-11-17T23:05:33.534687Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "ts = time()\n",
    "dff = df.join(df2, \"TransactionID\")\n",
    "te = time()\n",
    "s[\"merge\"] = te-ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T23:06:01.148952Z",
     "start_time": "2020-11-17T23:05:33.851490Z"
    }
   },
   "outputs": [],
   "source": [
    "# the difference is that we call collect method, which runs all the computations at this point\n",
    "#ts = time()\n",
    "#grp = dff.groupby([dff[\"isFraud\"],dff[\"ProductCD\"],dff[\"card4\"],dff[\"card6\"],dff[\"id_15\"],dff[\"id_31\"]]) \\\n",
    "#        .agg(avg(\"TransactionAmt\"), sum(\"TransactionAmt\"))\\\n",
    "#        .collect()\n",
    "#te = time()\n",
    "#s[\"aggregation\"] = te-ts\n",
    "#s[\"all\"] = te-tss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T23:13:24.332254Z",
     "start_time": "2020-11-17T23:13:03.641149Z"
    }
   },
   "outputs": [],
   "source": [
    "# the difference is that we call collect method, which runs all the computations at this point\n",
    "ts = time()\n",
    "grp = dff.groupby([\"isFraud\",\"ProductCD\",\"card4\",\"card6\",\"id_15\",\"id_31\"]) \\\n",
    "        .agg(avg(\"TransactionAmt\"), sum(\"TransactionAmt\"))\\\n",
    "        .collect()\n",
    "te = time()\n",
    "s[\"aggregation\"] = te-ts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = time()\n",
    "dff.orderBy(\"card1\",\"addr1\",\"D9\").collect()\n",
    "# alternatively\n",
    "# dff.sort(\"card1\",\"addr1\",\"D9\").collect()\n",
    "te = time()\n",
    "s[\"sorting\"] = te-ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T23:06:25.157340Z",
     "start_time": "2020-11-17T23:06:25.118349Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pandas</th>\n",
       "      <th>dask</th>\n",
       "      <th>dask_indexed</th>\n",
       "      <th>vaex</th>\n",
       "      <th>spark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>load_transactions</th>\n",
       "      <td>18.682878</td>\n",
       "      <td>0.059999</td>\n",
       "      <td>10.035912</td>\n",
       "      <td>17.666177</td>\n",
       "      <td>31.344823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>load_identity</th>\n",
       "      <td>0.550774</td>\n",
       "      <td>0.015863</td>\n",
       "      <td>0.569751</td>\n",
       "      <td>0.884425</td>\n",
       "      <td>1.417775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merge</th>\n",
       "      <td>2.118241</td>\n",
       "      <td>0.058240</td>\n",
       "      <td>0.049744</td>\n",
       "      <td>0.143270</td>\n",
       "      <td>0.244810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aggregation</th>\n",
       "      <td>0.066574</td>\n",
       "      <td>17.411429</td>\n",
       "      <td>15.891529</td>\n",
       "      <td>0.494523</td>\n",
       "      <td>16.870172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sorting</th>\n",
       "      <td>1.177349</td>\n",
       "      <td>49.431917</td>\n",
       "      <td>53.414108</td>\n",
       "      <td>1.108287</td>\n",
       "      <td>90.440744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>22.595816</td>\n",
       "      <td>66.977449</td>\n",
       "      <td>79.961045</td>\n",
       "      <td>20.296683</td>\n",
       "      <td>140.318324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      pandas       dask  dask_indexed       vaex       spark\n",
       "load_transactions  18.682878   0.059999     10.035912  17.666177   31.344823\n",
       "load_identity       0.550774   0.015863      0.569751   0.884425    1.417775\n",
       "merge               2.118241   0.058240      0.049744   0.143270    0.244810\n",
       "aggregation         0.066574  17.411429     15.891529   0.494523   16.870172\n",
       "sorting             1.177349  49.431917     53.414108   1.108287   90.440744\n",
       "Total              22.595816  66.977449     79.961045  20.296683  140.318324"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_df = pd.DataFrame(stats)\n",
    "stats_df.loc['Total'] = stats_df.sum()\n",
    "stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T22:16:19.569545Z",
     "start_time": "2020-11-17T22:16:19.559625Z"
    }
   },
   "source": [
    "# Modin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T22:57:15.609009Z",
     "start_time": "2020-11-17T22:57:15.586070Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.8.2'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T23:00:06.292260Z",
     "start_time": "2020-11-17T22:58:42.702035Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'isFraud'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: `DataFrame.groupby_on_multiple_columns` defaulting to pandas implementation.\n",
      "To request implementation, send an email to feature_requests@modin.org.\n",
      "FutureWarning: The `squeeze` parameter is deprecated and will be removed in a future version.\n"
     ]
    }
   ],
   "source": [
    "tool = \"modin\"\n",
    "stats[tool] = {}\n",
    "s = stats[tool]\n",
    "\n",
    "\n",
    "ts = time()\n",
    "df = mpd.read_csv(paths[0])\n",
    "te = time()\n",
    "s[\"load_transactions\"] = te-ts\n",
    "\n",
    "ts = time()\n",
    "df2 = mpd.read_csv(paths[1])\n",
    "te = time()\n",
    "s[\"load_identity\"] = te-ts\n",
    "\n",
    "ts = time()\n",
    "dff = df.merge(df2, on=\"TransactionID\")\n",
    "te = time()\n",
    "s[\"merge\"] = te-ts\n",
    "\n",
    "# modin defaults to pandas for multiple column aggregation and then fails on KeyError, though the key is available\n",
    "ts = time()\n",
    "try:\n",
    "    grp = dff.groupby([\"isFraud\",\"ProductCD\",\"card4\",\"card6\",\"id_15\",\"id_31\"])[\"TransactionAmt\"].agg([\"mean\",\"sum\"])\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "te = time()\n",
    "s[\"aggregation\"] = te-ts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T22:58:20.241434Z",
     "start_time": "2020-11-17T22:55:17.025Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pandas</th>\n",
       "      <th>dask</th>\n",
       "      <th>dask_indexed</th>\n",
       "      <th>vaex</th>\n",
       "      <th>spark</th>\n",
       "      <th>modin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>load_transactions</th>\n",
       "      <td>18.840576</td>\n",
       "      <td>0.056465</td>\n",
       "      <td>10.547130</td>\n",
       "      <td>16.921098</td>\n",
       "      <td>30.636420</td>\n",
       "      <td>13.851530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>load_identity</th>\n",
       "      <td>0.464806</td>\n",
       "      <td>0.016233</td>\n",
       "      <td>0.814531</td>\n",
       "      <td>0.738712</td>\n",
       "      <td>1.918626</td>\n",
       "      <td>0.509824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merge</th>\n",
       "      <td>1.954993</td>\n",
       "      <td>0.054572</td>\n",
       "      <td>0.045397</td>\n",
       "      <td>0.115304</td>\n",
       "      <td>0.347089</td>\n",
       "      <td>8.276430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aggregation</th>\n",
       "      <td>0.061256</td>\n",
       "      <td>12.940852</td>\n",
       "      <td>13.947035</td>\n",
       "      <td>0.412613</td>\n",
       "      <td>14.489696</td>\n",
       "      <td>0.152401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sorting</th>\n",
       "      <td>1.124379</td>\n",
       "      <td>36.934965</td>\n",
       "      <td>51.421090</td>\n",
       "      <td>1.124599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      pandas       dask  dask_indexed       vaex      spark  \\\n",
       "load_transactions  18.840576   0.056465     10.547130  16.921098  30.636420   \n",
       "load_identity       0.464806   0.016233      0.814531   0.738712   1.918626   \n",
       "merge               1.954993   0.054572      0.045397   0.115304   0.347089   \n",
       "aggregation         0.061256  12.940852     13.947035   0.412613  14.489696   \n",
       "sorting             1.124379  36.934965     51.421090   1.124599        NaN   \n",
       "\n",
       "                       modin  \n",
       "load_transactions  13.851530  \n",
       "load_identity       0.509824  \n",
       "merge               8.276430  \n",
       "aggregation         0.152401  \n",
       "sorting                  NaN  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T23:01:01.211911Z",
     "start_time": "2020-11-17T23:00:45.850513Z"
    }
   },
   "outputs": [],
   "source": [
    "clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(stats).to_csv(\"statistics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29.1, 18.8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use psutil to check for system resources\n",
    "psutil.cpu_percent(), psutil.virtual_memory().percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def system_resources(n, pause, cpu_threshold = 0.5, mem_threshold = 0.5):\n",
    "    \n",
    "    cpu_m = []\n",
    "    mem_m = []\n",
    "    cpu_treshold_breached = False\n",
    "    mem_treshold_breached = False\n",
    "    \n",
    "    for i in range(n):\n",
    "        cpu_m.append(psutil.cpu_percent())\n",
    "        mem_m.append(psutil.virtual_memory().percent)\n",
    "        sleep(pause)\n",
    "    cpu_m = np.mean(cpu_m)\n",
    "    mem_m = np.mean(mem_m)\n",
    "    \n",
    "    if cpu_m / 100 > cpu_threshold:\n",
    "        cpu_treshold_breached = True\n",
    "        \n",
    "    if mem_m / 100 > mem_threshold:\n",
    "        mem_treshold_breached = True\n",
    "    \n",
    "    return {\"cpu\": cpu_m, \"memory\": mem_m, \"cpu_threshold\": cpu_treshold_breached, \"mem_threshold\": mem_treshold_breached }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cpu': 13.133333333333333,\n",
       " 'memory': 18.799999999999997,\n",
       " 'cpu_threshold': False,\n",
       " 'mem_threshold': False}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_resources(3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Events:\n",
    "    \n",
    "    def __init__(self, path):\n",
    "        self.file = open(path, 'a', encoding='utf-8')\n",
    "        \n",
    "    def log(self, time, tool, operation, duration):\n",
    "        print(\"|\".join([strftime('%Y-%m-%d %H:%M:%S', localtime(te)),tool,operation,str(duration)])+\"\\n\")\n",
    "        print(self.file)\n",
    "        self.file.write(\"|\".join([strftime('%Y-%m-%d %H:%M:%S', localtime(te)),tool,operation,str(duration)])+\"\\n\")\n",
    "        \n",
    "    def close(self):\n",
    "        self.file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = Events(\"example.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-14 00:18:56|pandas|load|0.48686718940734863\n",
      "\n",
      "<_io.TextIOWrapper name='example.log' mode='a' encoding='utf-8'>\n"
     ]
    }
   ],
   "source": [
    "ts = time()\n",
    "df = pd.read_csv(paths[1])\n",
    "te = time()\n",
    "logger.log(te, \"pandas\", \"load\",  te-ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.file.write(\"|\".join([strftime('%Y-%m-%d %H:%M:%S', localtime(te)),\"pandas\",\"load\",str(ts-te)])+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-01-13 23:38:59'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te = time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(filename='/home/vaclav/Notebooks/Medium/DataFrames/lexample.log', encoding='utf-8', level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:MainThread:root:This is an info message\n"
     ]
    }
   ],
   "source": [
    "logging.info('This is an info message')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "big-tables",
   "language": "python",
   "name": "big-tables"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
